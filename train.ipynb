{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from keras_unet.models.custom_unet import conv2d_block, custom_unet\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping,CSVLogger\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "\n",
    "DATA_PATH = './data/'\n",
    "FRAME_PATH = DATA_PATH+'/images/'\n",
    "MASK_PATH = DATA_PATH+'/masks/'\n",
    "seed =42\n",
    "model_path='./saved_weights/model_v1.h5'\n",
    "log_path = './log.out'\n",
    "epochs = 2\n",
    "bs = 16\n",
    "num_classes =2\n",
    "\n",
    "label_codes=[(255, 255, 255), (0, 0, 0)]\n",
    "label_names=['building', 'background']\n",
    "\n",
    "# Create folders to hold images and masks per data split\n",
    "folders = ['train_frames/train', 'train_masks/train', 'val_frames/val', 'val_masks/val', 'test_frames/test', 'test_masks/test']\n",
    "            \n",
    "for folder in folders:\n",
    "    if not os.path.exists(DATA_PATH + folder):\n",
    "        os.makedirs(DATA_PATH + folder)\n",
    "\n",
    "#Get all frames and masks, sort them, shuffle them to generate data splits.\n",
    "all_frames = os.listdir(FRAME_PATH)\n",
    "all_masks = os.listdir(MASK_PATH)\n",
    "\n",
    "\n",
    "all_frames.sort(key=lambda var:[int(x) if x.isdigit() else x \n",
    "                                for x in re.findall(r'[^0-9]|[0-9]+', var)])\n",
    "all_masks.sort(key=lambda var:[int(x) if x.isdigit() else x \n",
    "                               for x in re.findall(r'[^0-9]|[0-9]+', var)])\n",
    "\n",
    "random.seed(seed)\n",
    "random.shuffle(all_frames)\n",
    "\n",
    "# Generate train, val, and test sets for frames train-val-test:60-20-20\n",
    "train_split = int(0.6*len(all_frames))\n",
    "val_split = int(0.8 * len(all_frames))\n",
    "\n",
    "train_frames = all_frames[:train_split]\n",
    "val_frames = all_frames[train_split:val_split]\n",
    "test_frames = all_frames[val_split:]\n",
    "\n",
    "\n",
    "# Generate corresponding mask lists for masks\n",
    "train_masks = [f for f in all_masks if f in train_frames]\n",
    "val_masks = [f for f in all_masks if f in val_frames]\n",
    "test_masks = [f for f in all_masks if f in test_frames]\n",
    "\n",
    "\n",
    "#Add train, val, test frames and masks to relevant folders\n",
    "def add_frames(dir_name, image):\n",
    "  \n",
    "    img = Image.open(FRAME_PATH+image)\n",
    "    img.save(DATA_PATH+'/{}'.format(dir_name)+'/'+image)\n",
    "\n",
    "def add_masks(dir_name, image):\n",
    "  \n",
    "    img = Image.open(MASK_PATH+image)\n",
    "    img.save(DATA_PATH+'/{}'.format(dir_name)+'/'+image)\n",
    "    \n",
    "    \n",
    "frame_folders = [(train_frames, 'train_frames/train'), (val_frames, 'val_frames/val'), \n",
    "                 (test_frames, 'test_frames/test')]\n",
    "\n",
    "mask_folders = [(train_masks, 'train_masks/train'), (val_masks, 'val_masks/val'), \n",
    "                (test_masks, 'test_masks/test')]\n",
    "\n",
    "# Add frames\n",
    "for folder in frame_folders:\n",
    "  \n",
    "    array = folder[0]\n",
    "    name = [folder[1]] * len(array)\n",
    "\n",
    "    list(map(add_frames, name, array))\n",
    "\n",
    "# Add masks\n",
    "for folder in mask_folders:\n",
    "  \n",
    "    array = folder[0]\n",
    "    name = [folder[1]] * len(array)\n",
    "\n",
    "    list(map(add_masks, name, array))\n",
    "    \n",
    "\n",
    "##Helper functions for converting label codes to names\n",
    "id2code = {k:v for k,v in enumerate(label_codes)}\n",
    "\n",
    "def rgb_to_onehot(rgb_image, colormap = id2code):\n",
    "    '''Function to one hot encode RGB mask labels\n",
    "        Inputs: \n",
    "            rgb_image - image matrix (eg. 256 x 256 x 3 dimension numpy ndarray)\n",
    "            colormap - dictionary of color to label id\n",
    "        Output: One hot encoded image of dimensions (height x width x num_classes) where num_classes = len(colormap)\n",
    "    '''\n",
    "    num_classes = len(colormap)\n",
    "    shape = rgb_image.shape[:2]+(num_classes,)\n",
    "    encoded_image = np.zeros( shape, dtype=np.int8 )\n",
    "    for i, cls in enumerate(colormap):\n",
    "        encoded_image[:,:,i] = np.all(rgb_image.reshape( (-1,3) ) == colormap[i], axis=1).reshape(shape[:2])\n",
    "    return encoded_image\n",
    "\n",
    "\n",
    "def onehot_to_rgb(onehot, colormap = id2code):\n",
    "    '''Function to decode encoded mask labels\n",
    "        Inputs: \n",
    "            onehot - one hot encoded image matrix (height x width x num_classes)\n",
    "            colormap - dictionary of color to label id\n",
    "        Output: Decoded RGB image (height x width x 3) \n",
    "    '''\n",
    "    single_layer = np.argmax(onehot, axis=-1)\n",
    "    output = np.zeros( onehot.shape[:2]+(3,) )\n",
    "    for k in colormap.keys():\n",
    "        output[single_layer==k] = colormap[k]\n",
    "    return np.uint8(output)\n",
    "\n",
    "# Normalizing only frame images, since masks contain label info\n",
    "data_gen_args = dict(rescale=1./255)\n",
    "mask_gen_args = dict()\n",
    "\n",
    "train_frames_datagen = ImageDataGenerator(**data_gen_args)\n",
    "train_masks_datagen = ImageDataGenerator(**mask_gen_args)\n",
    "val_frames_datagen = ImageDataGenerator(**data_gen_args)\n",
    "val_masks_datagen = ImageDataGenerator(**mask_gen_args)\n",
    "\n",
    "def TrainAugmentGenerator(seed=seed, batch_size = bs):\n",
    "    '''Train Image data generator\n",
    "        Inputs: \n",
    "            seed - seed provided to the flow_from_directory function to ensure aligned data flow\n",
    "            batch_size - number of images to import at a time\n",
    "        Output: Decoded RGB image (height x width x 3) \n",
    "    '''\n",
    "    train_image_generator = train_frames_datagen.flow_from_directory(\n",
    "    DATA_PATH + 'train_frames/',\n",
    "    batch_size = batch_size, seed = seed)\n",
    "\n",
    "    train_mask_generator = train_masks_datagen.flow_from_directory(\n",
    "    DATA_PATH + 'train_masks/',\n",
    "    batch_size = batch_size, seed = seed)\n",
    "\n",
    "    while True:\n",
    "        X1i = train_image_generator.next()\n",
    "        X2i = train_mask_generator.next()\n",
    "        \n",
    "        #One hot encoding RGB images\n",
    "        mask_encoded = [rgb_to_onehot(X2i[0][x,:,:,:], id2code) for x in range(X2i[0].shape[0])]\n",
    "        \n",
    "        yield X1i[0], np.asarray(mask_encoded)\n",
    "\n",
    "def ValAugmentGenerator(seed=seed, batch_size = bs):\n",
    "    '''Validation Image data generator\n",
    "        Inputs: \n",
    "            seed - seed provided to the flow_from_directory function to ensure aligned data flow\n",
    "            batch_size - number of images to import at a time\n",
    "        Output: Decoded RGB image (height x width x 3) \n",
    "    '''\n",
    "    val_image_generator = val_frames_datagen.flow_from_directory(\n",
    "    DATA_PATH + 'val_frames/',\n",
    "    batch_size = batch_size, seed = seed)\n",
    "\n",
    "\n",
    "    val_mask_generator = val_masks_datagen.flow_from_directory(\n",
    "    DATA_PATH + 'val_masks/',\n",
    "    batch_size = batch_size, seed = seed)\n",
    "\n",
    "\n",
    "    while True:\n",
    "        X1i = val_image_generator.next()\n",
    "        X2i = val_mask_generator.next()\n",
    "        \n",
    "        #One hot encoding RGB images\n",
    "        mask_encoded = [rgb_to_onehot(X2i[0][x,:,:,:], id2code) for x in range(X2i[0].shape[0])]\n",
    "        \n",
    "        yield X1i[0], np.asarray(mask_encoded)\n",
    "        \n",
    "\n",
    "\n",
    "model = custom_unet(\n",
    "    (256,256,3),\n",
    "    num_classes=num_classes,\n",
    "    activation=\"relu\",\n",
    "    use_batch_norm=True,\n",
    "    upsample_mode=\"deconv\",\n",
    "    dropout=0.3,\n",
    "    dropout_change_per_layer=0.0,\n",
    "    dropout_type=\"spatial\",\n",
    "    use_dropout_on_upsampling=True,\n",
    "    use_attention=True,\n",
    "    filters=16,\n",
    "    num_layers=4,\n",
    "    output_activation=\"sigmoid\")\n",
    "   \n",
    "\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',\n",
    "              metrics=['accuracy',tf.keras.metrics.MeanIoU(num_classes=num_classes)])\n",
    "\n",
    "plot_model(model,to_file='./visualizations/model_unet_w_att.png',show_shapes=True)\n",
    "\n",
    "checkpoint = ModelCheckpoint(model_path, monitor='val_loss', \n",
    "                             verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "csv_logger = CSVLogger(log_path, append=True, separator=';')\n",
    "\n",
    "earlystopping = EarlyStopping(monitor = 'val_accuracy', verbose = 1,\n",
    "                              min_delta = 0.01, patience = 3, mode = 'max')\n",
    "\n",
    "callbacks = [checkpoint, csv_logger, earlystopping]\n",
    "\n",
    "vs = (len(os.listdir('./data/val_frames/val/'))//bs)\n",
    "ts = (len(os.listdir('./data/train_frames/train/'))//bs)\n",
    "model.summary()\n",
    "\n",
    "\n",
    "result = model.fit_generator(TrainAugmentGenerator(seed,bs), epochs=epochs, \n",
    "                          steps_per_epoch = ts,\n",
    "                          validation_data=ValAugmentGenerator(seed,bs), \n",
    "                          validation_steps=vs, \n",
    "                          callbacks=callbacks)\n",
    "\n",
    "model.save(model_path)\n",
    "# Get actual number of epochs model was trained for\n",
    "N = len(result.history['loss'])\n",
    "\n",
    "#Plot the model evaluation history\n",
    "plt.style.use(\"ggplot\")\n",
    "fig = plt.figure(figsize=(20,8))\n",
    "\n",
    "fig.add_subplot(1,2,1)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(np.arange(0, N), result.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), result.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "\n",
    "# fig.add_subplot(1,3,2)\n",
    "# plt.title(\"Mean Intersection Over Union\")\n",
    "# plt.plot(np.arange(0, N), result.history[\"mean_io_u_6\"], label=\"train_miou\")\n",
    "# plt.plot(np.arange(0, N), result.history[\"val_mean_io_u_6\"], label=\"val_miou\")\n",
    "# plt.ylim(-1,1)\n",
    "\n",
    "fig.add_subplot(1,2,2)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(np.arange(0, N), result.history[\"accuracy\"], label=\"train_accuracy\")\n",
    "plt.plot(np.arange(0, N), result.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.xlabel(\"Epoch #\")\n",
    "#plt.ylabel(\"\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig('./visualizations/eval_during_train.png')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
